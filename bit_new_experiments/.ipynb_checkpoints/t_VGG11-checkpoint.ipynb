{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to local/data/Xian/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c258e75ac5a42068ee62d81344cdcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting local/data/Xian/cifar10/cifar-10-python.tar.gz to local/data/Xian/cifar10\n",
      "Files already downloaded and verified\n",
      "Run on GPU...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PrunedConv' object has no attribute 'set_up'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c872a1bf395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    229\u001b[0m                          \u001b[0mset_bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                          \u001b[0mmask_bit_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_bit_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                          q=q,epochs = 20)\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mlist_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6c872a1bf395>\u001b[0m in \u001b[0;36mtrain_\u001b[0;34m(train_set, test_set, layer_name, q, set_bit, mask_bit_position, epochs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPrunedConv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_bit_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset_bit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mlayer_num\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPruneLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrunedConv' object has no attribute 'set_up'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "# import os\n",
    "import shutil\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from prune_layer_bit_new import *\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            PruneLinear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            PruneLinear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            PruneLinear(512, 10),\n",
    "        )\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = PrunedConv(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def get_num_correct(pred,labels):\n",
    "    return pred.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def Net():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "    return VGG(make_layers(cfg['A']))\n",
    "    \n",
    "    \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "])\n",
    "train_set=torchvision.datasets.CIFAR10(\n",
    "    root='~/work/data/Xian/cifar10',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train)\n",
    "\n",
    "\n",
    "test_set=torchvision.datasets.CIFAR10(\n",
    "    root='~/work/data/Xian/cifar10',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test)\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(\"Run on GPU...\")\n",
    "else:\n",
    "    print(\"Run on CPU...\")\n",
    "\n",
    "len_bits = 1+FB+IB\n",
    "IB = 4\n",
    "FB = 11\n",
    "\n",
    "def train_(train_set,test_set,layer_name, q, set_bit = 0, mask_bit_position = [1]*16, epochs = 10):\n",
    "    torch.manual_seed(1)\n",
    "    train_loader=torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=False, pin_memory=True,num_workers=2)\n",
    "    test_loader=torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, pin_memory=True,num_workers=2)\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    network= Net().to(device)\n",
    "    network.apply(init_weights)\n",
    "                \n",
    "\n",
    "    optimizer = optim.SGD(network.parameters(), lr=0.1, weight_decay=0.0005)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,60,80], gamma=0.1)\n",
    "\n",
    "    layer_num = 1\n",
    "    for n, m in network.named_modules():\n",
    "        if isinstance(m,PrunedConv):\n",
    "            if layer_num in layer_name:\n",
    "                m.set_up(mask_bit_position,q,set_bit)\n",
    "            layer_num +=1\n",
    "        if isinstance(m,PruneLinear):\n",
    "            if layer_num in layer_name:\n",
    "                m.set_up(mask_bit_position,q,set_bit)\n",
    "            layer_num +=1\n",
    "\n",
    "    acc_train=[]\n",
    "    acc_test=[]\n",
    "    acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        network.train()\n",
    "        count_in = 0\n",
    "\n",
    "        for batch in train_loader: #Get batch\n",
    "\n",
    "            count_in = count_in + 1\n",
    "            images,labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Do bit maskinn\n",
    "            layer_num = 1\n",
    "            for n, m in network.named_modules():\n",
    "                if isinstance(m,PrunedConv):\n",
    "                    if layer_num in layer_name:\n",
    "                        m.prune_by_percentage()\n",
    "                    layer_num +=1\n",
    "                if isinstance(m,PruneLinear):\n",
    "                    if layer_num in layer_name:\n",
    "                         m.prune_by_percentage()\n",
    "                    layer_num +=1\n",
    "\n",
    "            preds=network(images) #pass batch to network\n",
    "            correct = get_num_correct(preds, labels)\n",
    "            loss = criterion(preds,labels) #Calculate loss\n",
    "            loss.backward() #Calculate gradients\n",
    "            optimizer.step() #Update weights\n",
    "            total_correct+=correct\n",
    "            \n",
    "        print(\"epoch: \", epoch,  \"total_correct: \", total_correct)\n",
    "        print(\"training accuracy: \", total_correct/len(train_set))\n",
    "        acc_train.append(deepcopy(float(total_correct)/len(train_set)))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            correct_test=0\n",
    "            for batch_test in test_loader: #Get batch\n",
    "                images_test,labels_test = batch_test\n",
    "                images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "                preds_test=network(images_test) #pass batch to network\n",
    "                correct_test += get_num_correct(preds_test, labels_test)\n",
    "            print(\"testing accuracy: \", correct_test / len(test_set))\n",
    "            if epoch == epochs - 1:\n",
    "                print(correct_test / len(test_set))\n",
    "                acc = correct_test / len(test_set) \n",
    "            acc_test.append(deepcopy(float(correct_test)/len(test_set)))\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "    return acc\n",
    "\n",
    "list_q = [10]\n",
    "list_mask = [2]\n",
    "list_acc = []\n",
    "list_layers =[8]\n",
    "for layer_name in list_layers:\n",
    "    for q in list_q:\n",
    "        for j in list_mask:\n",
    "            mask_bit_position = [1]*16\n",
    "            mask_bit_position[j] = 0\n",
    "            acc = train_(train_set,test_set,layer_name=[layer_name],\n",
    "                         set_bit = 0,\n",
    "                         mask_bit_position = mask_bit_position, \n",
    "                         q=q,epochs = 20)\n",
    "            list_acc += [acc]\n",
    "            print(list_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
